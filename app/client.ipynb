{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local LLM\n",
    "\n",
    "Here, we'll use a server that's serving a local LLM.\n",
    "\n",
    "**Attention** This is OK for prototyping / dev usage, but should not be used for production cases when there might be concurrent requests from different users. As of the time of writing, Ollama is designed for single user and cannot handle concurrent requests see this issue: https://github.com/ollama/ollama/issues/358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "model = RemoteRunnable(\"http://localhost:8000/ollama/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the standard interface of a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Tell me a joke about cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, so I need to come up with a joke about cats. Hmm, where do I start? Maybe I can think of something common that people like to say about cats. Oh, wait, \"Do cats really have hearts?\" That\\'s always been on my mind.\\n\\nI should explain why that\\'s funny or appropriate. So, if you cut their tail, they lose their tails, right? But in a cat\\'s case, it\\'s more about losing their mius rather than their heart. That\\'s actually an interesting point because not all animals have hearts, so cats definitely don\\'t either.\\n\\nBut wait, the joke is trying to play on words there. It\\'s a pun on \"tail\" and \"heart,\" so that creates some humor. I need to make sure it makes sense but also isn\\'t obvious. The setup gives a reason for the punchline, making it relatable and funny.\\n\\nI think this works because it uses a wordplay that people often find amusingâ€”mixing animal-related words in a humorous way. It\\'s simple enough for anyone to understand but still maintains that playful tone of jokes.\\n</think>\\n\\nSure! Here\\'s a lighthearted joke about cats:\\n\\nWhy did the cat get lost?  \\nBecause its tail couldn\\'t catch up to it!\\n\\n---\\n\\nThis joke plays on the wordplay between \"tail\" and \"heart,\" playing on the idea of losing something, both literally (cuts the tail) and metaphorically.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-02-16T10:46:10.656328Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20026139690, 'load_duration': 2149902931, 'prompt_eval_count': 9, 'prompt_eval_duration': 298000000, 'eval_count': 297, 'eval_duration': 17576000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-6957a0c6-cf76-4304-bf84-d9edfe57c89a-0', usage_metadata={'input_tokens': 9, 'output_tokens': 297, 'total_tokens': 306})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so I need to come up with a three-sentence story about a cat. Let me think about how to approach this. First, the topic is cats, which are pretty common pets but can have various personalities and traits. Maybe I should focus on something relatable or interesting to make it engaging.\\n\\nI remember that cats are often depicted as loyal and protective, so perhaps I can center around their loyalty or maybe something like a problem they face. The three-sentence limit is tight, so each sentence needs to be concise yet impactful.\\n\\nLet me outline possible elements: the cat\\'s appearance, their personality traits, and how they interact with others. For example, if I focus on their protective nature, showing them caring for a friend or family member. That could work well because it introduces a problem (the cat acting alone) that needs solving through the cat\\'s actions.\\n\\nNow, structuring this into three sentences: first introducing the situation where the cat is out of town or alone, second showing how the cat notices and starts taking action, and third possibly resolving the issue with their response. That should make sense within the limit.\\n\\nWait, let me check if that flows well. Start by setting up the problem, then introduce the solution through their actions, and then maybe they do something to fix it or move on. Yeah, that seems logical.\\n\\nI should also make sure each sentence is clear without being too wordy. Maybe use simple words so it\\'s easy to understand. Let me try putting this together: \"The cat was away from home for an hour, noticing a lost toy in the living room.\" Then, \"She quickly reached into her bag and grabbed the missing ball with care.\" Finally, \"She gave him a warm embrace, feeling good about finding her friend again.\"\\n\\nHmm, that\\'s three sentences. It introduces a problem, shows resolution through action, and ends on a positive note. I think this covers all aspects of a cat story within the constraints.\\n</think>\\n\\nThe cat was away from home for an hour, noticing a lost toy in the living room. She quickly reached into her bag and grabbed the missing ball with care. She gave him a warm embrace, feeling good about finding her friend again.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-02-15T16:10:15.699759Z', 'done': True, 'done_reason': 'stop', 'total_duration': 28591936074, 'load_duration': 35370258, 'prompt_eval_count': 14, 'prompt_eval_duration': 91000000, 'eval_count': 451, 'eval_duration': 28463000000, 'message': {'role': 'assistant', 'content': '', 'images': None, 'tool_calls': None}}, id='run-ac9d62d7-dd16-4dcf-ab08-4c9f7c2899a1-0', usage_metadata={'input_tokens': 14, 'output_tokens': 451, 'total_tokens': 465})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched API works, but b/c ollama does not support parallelism, it's no faster than using .invoke twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.65 ms, sys: 6.57 ms, total: 14.2 ms\n",
      "Wall time: 5.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='\\nSure! Here is a three sentence story about a cat:\\n\\nMr. Whiskers was a sleek black cat with bright green eyes. He spent his days lounging in the sunbeams that streamed through the living room window, chasing the occasional fly, and purring contentedly. Despite his lazy demeanor, Mr. Whiskers was always on the lookout for a warm lap to curl up in.'),\n",
       " AIMessage(content='\\nSure! Here is a three sentence story about a cat:\\n\\nMittens the cat purred contentedly on the windowsill, basking in the warm sunlight that streamed through the glass. Suddenly, a tiny bird perched on the ledge outside, tweeting nervously as it eyed the cat with suspicion. Without hesitation, Mittens pounced, snatching the bird in mid-air and devouring it in one quick motion.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.batch([prompt, prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.72 ms, sys: 7.59 ms, total: 17.3 ms\n",
      "Wall time: 5.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(2):\n",
    "    model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"\\nSure, here's a three sentence story about a cat:\\n\\nMittens the cat purred contentedly on the windowsill, basking in the warm sunlight that streamed through the glass. Her bright green eyes sparkled as she watched a bird flit and flutter outside, wishing she could join it in its flight. Just then, her owner entered the room with a bowl of creamy milk, causing Mittens to jump down from the windowsill and rub against their legs in excitement.\"),\n",
       " AIMessage(content='\\nSure! Here is a three sentence story about a cat:\\n\\nMittens the cat purred contentedly on my lap, her soft fur a soothing balm for my frazzled nerves. As I stroked her back, she gazed up at me with big, round eyes, purring even louder. It was hard to resist the charm of this little ball of fluff, and I found myself smiling and scratching behind her ears.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.abatch([prompt, prompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming is available by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|S|ure|,| here| is| a| |3| sentence| story| about| a| cat|:|\n",
      "|\n",
      "|M|itt|ens| the| cat| pur|red| content|edly| on| the| windows|ill|,| her| tail| tw|itch|ing| as| she| watched| the| birds| outside|.| Sud|den|ly|,| a| squ|ir|rel| sc|am|per|ed| by| and| Mitt|ens| was| on| high| alert|,| her| ears| per|ked| up| and| ready| to| p|ounce|.| With| light|ning| quick| ref|lex|es|,| Mitt|ens| jump|ed| from| the| windows|ill| and| ch|ased| after| the| squ|ir|rel|,| her| tail| streaming| behind| her|.||"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(prompt):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|The| cat| pur|red| content|edly| on| my| lap|,| its| soft| fur| a| so|othing| bal|m| for| my| fra|zz|led| n|erves|.| As| I| st|rok|ed| its| back|,| it| gaz|ed| up| at| me| with| soul|ful| eyes|,| p|urr|ing| loud|ly| in| appro|val|.| In| that| moment|,| all| was| right| with| the| world|.||"
     ]
    }
   ],
   "source": [
    "async for chunk in model.astream(prompt):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so is the event stream API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'name': '/ollama', 'tags': [], 'metadata': {}, 'data': {'input': 'Tell me a 3 sentence story about a cat.'}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content='\\n')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content='S')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content='ure')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=',')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' here')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' is')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' a')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' ')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content='3')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' sentence')}}\n",
      "{'event': 'on_chat_model_stream', 'run_id': '6c2bdfc1-d482-4861-886c-c737a50771c3', 'tags': [], 'metadata': {}, 'name': '/ollama', 'data': {'chunk': AIMessageChunk(content=' story')}}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "async for event in model.astream_events(prompt, version='v1'):\n",
    "    print(event)\n",
    "    if i > 10:\n",
    "        print('...')\n",
    "        break\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
